---
title: "Movielens Recommendation System"
author: "Dr. Ivan S. Zapreev"
date: "`r format(Sys.Date())`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(tidyverse)
library(lubridate)

MOVIELENS_DATA_FILE_NAME <- "movielens_data.rda"
MOVIELENS_REPORT_FILE_NAME <- "movielens_report.rda"

load(MOVIELENS_DATA_FILE_NAME)
load(MOVIELENS_REPORT_FILE_NAME)
```

*[According to Wikipedia](https://en.wikipedia.org/wiki/Recommender_system):*

> A recommender system or a recommendation system (sometimes replacing 'system' with a synonym such as platform or engine) is a subclass of information filtering system that seeks to predict the "rating" or "preference" a user would give to an item.

## Introduction
<!--an introduction/overview/executive summary section that describes the dataset and summarizes the goal of the project and key steps that were performed-->

Recommendation systems are widely used in commercial application to provide targeted commercials or suggest online content. In the latter, one can think of *Spotify* suggesting songs or *Youtube* proposing videos. The main goal of a recommendation system is to accurately predict client's preferences, based on available data on the previous user behavior. Note that, such data includes the bahaviour of all the clients.

The goal of this work is to build a movie recommendation system based on the `r movielens_report$data_set_name` available from [`r movielens_report$data_set_site_url`](`r movielens_report$data_set_site_url`). To reach our goal we will use supervised machine learning techniques studied within the *"PH125.8x Data Science: Machine Learning"* course (a part of the broader HarvardX *Data Science Professional* certification program). The recommendation system will be therefore based on (linear) statistical models trained on the subset of the `r movielens_report$data_set_name`.

The rest of the document is organized as follows. The *"Analysis"* section explains the process and techniques used, such as data cleaning, data exploration and visualization, any insights gained, and your modeling approach. The *"Results"* presents the modeling results and discusses the model performance. The *"Conclusions"* section gives a brief summary of the report, its limitations and future work.

The remainder of this section first present the data set, next analyze the dataset properties, then defines the goal of this project more concretely, and finally identifies the main steps that have been taken to reach the goal.

### Dataset overview
As stated in the [README](http://files.grouplens.org/datasets/movielens/ml-10m-README.html) of the original `r movielens_report$data_set_name`, it contains `10000054` ratings and `95580` tags (not used in this study) applied to `10681` movies by `71567` users of the [MovieLens](http://www.movielens.org/) service. 

All ratings are contained in the file `ml-10M100K/ratings.dat`. Each line of this file represents one rating specified by the rating value (`rating`), the movie identifier (`movieId`), the identifier of the user (`userId`) and the submission timestamp (`timestamp`). Ratings are made on a `5`-star scale, with half-star increments. Timestamps represent seconds since midnight *Coordinated Universal Time (UTC) of January 1, 1970*. 

Movie information is contained in the file `ml-10M100K/movies.dat`. Each line of this file represents one movie specified by its identifier (`movieId`), movie title (`title`) and the corresponding genres (`genres`). The movie titles are entered manually, so errors and inconsistencies may exist. Genres are pipe-separated lists, of the individual genres from the following set:

  `("Action", "Adventure", "Animation", "Children's", "Comedy", "Crime", "Documentary", "Drama", "Fantasy", "Film-Noir", "Horror", "Musical", "Mystery", "Romance", "Sci-Fi", "Thriller", "War", "Western")`.

In this project, we use a pre-processed subset of the original dataset, using only the data from the `ratings.dat` and `movies.dat` files thereof. To facilitate supervised learning, the data is pre-processed in the following way:

1. The `ratings.dat` and `movies.dat` are loaded into `ratings` and `movies` data frames
    1. `ratings` -- with columns named `r c("userId", "movieId", "rating", "timestamp")`
    2. `movies` -- columns named `r c("movieId", "title", "genres")`
2. The ratings are coupled with the movies information by the `movieId` into a new `movielens` data frame
3. The `movielens` data frame is randomly split into two parts:
    2. `edx` -- a training set storing the `90%` of the observations from the `movielens`
    1. `validation` -- a testing set storing the `10%` of the observations from the `movielens`
4. The `validation` set is filtered to only contain movies ans users present in `edx`
5. The observations filtered out in the previous step are added back to the `edx` set

For more details, see the `create_movielens_sets` function located in the `movielens_project.R` script. As a result of pre-processing we have two sets with the following metrics, the training set `edx`:

```{r, echo=F}
as_tibble(movielens_report$edx)
```

and the testing set `validation`:

```{r, echo=F}
as_tibble(movielens_report$validation)
```

```{r, echo=F}
percent_obs_edx <- round(movielens_report$edx$num_observations/(movielens_report$edx$num_observations+movielens_report$validation$num_observations)*100)
```
As one can see the `edx` set stores `r percent_obs_edx`% of the total number of observations (`num_observations`) and the `validation` set contains `r 100-percent_obs_edx`%. The difference in the numer of distinct movies (`num_movies`) and the number of distinct users (`num_users`) is explained by the observations being moved back from `validation` to `edx` in the last data preprocessing step, described above.

### Dataset analysis

Note that, from the number of distinct user, movies and observations (ratings) in the `edx` set it is clear that not every user has rated every movie as `r movielens_report$edx$num_users` \* `r movielens_report$edx$num_movies` < `r movielens_report$edx$num_observations`. The same can be seen via the next plot for randomly sampled `100` unique users and `100` unique movies:

```{r, echo=F}
#Sample 100 individual movie ids
movie_ids <- unique(movielens_data$edx$movieId)
sample_movie_ids <- sample(movie_ids, 100)

#Plot the sparse matrix
movielens_data$edx %>%
  filter(movieId %in% sample_movie_ids) %>% 
  select(userId, movieId, rating) %>%
  mutate(rating = 100) %>%
  spread(userId, rating) %>%
  select(sample(ncol(.), 100)) %>% #Here we sample a 100 individual user ids
  as.matrix() %>%
  t(.) %>%
  image(1:100, 1:100, . , xlab="Users", ylab="Movies")
abline(h=0:100+0.5, v=0:100+0.5, col = "grey")
```

The the task of a recommendation system we are to build can be seen as filling in the missing ratings.
To stress the complexity of the undertaking, below we list a number of different circumstances that can influence rating predictions, and may need to be taken into account when building the statistical model.

**(I)** Some movies are rated more often than the others:

```{r}
movielens_data$edx %>% 
  count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Movie rating counts")
```

**(II)** Some users are more active in rating movies that the others:

```{r}
movielens_data$edx %>%
  count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Users rating counts")
```

**(III)** Movies differ from eachother in given ratings, lets consider `10` movies with at least `100` ratings each:

```{r}
#Sample 10 individual movie ids for the movies with more than 100 ratings
movie_ids <- movielens_data$edx %>%
  group_by(movieId) %>% summarise(cnt = n()) %>% 
  filter(cnt > 100) %>% pull(movieId) %>% unique(.)
set.seed(1)
sample_movie_ids <- sample(movie_ids, 10)

#Use the boxplot to show variations in ratings between different movies
movielens_data$edx %>% 
  filter(movieId %in% sample_movie_ids) %>% 
  ggplot(aes(title, rating, group=movieId)) +
  geom_boxplot() +
  scale_x_discrete(labels = paste("movieId ",as.character(sample_movie_ids)))+
  theme(axis.text.x = element_text(angle = 20)) + 
  labs(x = "Selected movies")
```

**(IV)** Users differ from each other in giving ratings, lets consider `10` users with at least `100` ratings each:

```{r}
#Sample 10 individual user ids for the users with more than 100 ratings
user_ids <- movielens_data$edx %>%
  group_by(userId) %>% summarise(cnt = n()) %>% 
  filter(cnt > 100) %>% pull(userId) %>% unique(.)
set.seed(1)
sample_user_ids <- sample(user_ids, 10)

#Use the boxplot to show variations in ratings between different users
movielens_data$edx %>% 
  filter(userId %in% sample_user_ids) %>% 
  mutate(userName = paste("userId ", as.character(userId))) %>%
  group_by(userId) %>%
  ggplot(aes(userName, rating, group=userId)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 20)) +
  labs(x = "Selected users")
```

**(V)** The rating scores depend on the time when the rating is given:

```{r}
#Convert the timestamp into a week (date) and then plot 
#the mean rating for all the movies per week
movielens_data$edx %>%
  mutate(date = as_datetime(timestamp), week = round_date(date, "week")) %>%
  group_by(week) %>%
  summarize(avg_rating = mean(rating)) %>%
  ggplot(aes(week, avg_rating)) +
  geom_line() +
  geom_smooth(method = 'loess')
```

```{r, echo=F}
#Per movie, get the average movies score and rating counts
avg_movie_ratings <- movielens_data$edx %>%
  group_by(movieId) %>%
  summarize(avg_rating = mean(rating),
            num_ratings = n()) %>%
  arrange(desc(avg_rating))
```

**(VI)** The best and the worst (on-average) movies were not rated very often:

```{r}
#Get the movies with the top 10 average scores
true_top_10 <- avg_movie_ratings %>%
  arrange(desc(avg_rating)) %>% 
  slice(1:10)
true_top_10

#Get the movies with the bottom 10 average scores
true_bottom_10 <- avg_movie_ratings %>%
  arrange(avg_rating) %>% 
  slice(1:10)
true_bottom_10
```

See also the next plot where the best movies are marked as blue and the worst as red:
```{r}
#Plot the movies
avg_movie_ratings %>%
  ggplot(aes(x = num_ratings, y = avg_rating)) +
  geom_point(aes(color = I("black")), alpha=0.2)+
  geom_point(data = true_top_10, aes(num_ratings, avg_rating), color="blue") +
  geom_point(data = true_bottom_10, aes(num_ratings, avg_rating), color="red")
```

As we see from the plot above, there is more variability in the movies with fewer ratings but above that, the movies that are rated more often also seem to be on-average rated higher:
```{r}
#Plot the movies
avg_movie_ratings %>%
  ggplot(aes(x = num_ratings, y = avg_rating)) +
  geom_point(aes(color = I("black")), alpha=0.2) +
  geom_smooth()
```

### Project goal

### Execution plan

## Analysis
<!--a methods/analysis section that explains the process and techniques used, such as data cleaning, data exploration and visualization, any insights gained, and your modeling approach-->

## Results
<!--a results section that presents the modeling results and discusses the model performance-->

## Conclusions
<!--a conclusion section that gives a brief summary of the report, its limitations and future work (the last two are recommended but not necessary)-->
