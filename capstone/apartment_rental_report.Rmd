---
title: "Apartment Rental Prediction System"
author: "Dr. Ivan S. Zapreev"
date: "`r format(Sys.Date())`"
output: pdf_document
number_sections: true
toc: true
---

```{r setup, include=FALSE}

if(!require(tidyr)) install.packages("tidyr", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(outliers)) install.packages("outliers", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(graphics)) install.packages("graphics", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(tidyr)
library(lubridate)
library(ggplot2)
library(caret)
library(dslabs)
library(data.table)
library(dplyr)
library(outliers)
library(knitr)
library(graphics)
library(kableExtra)

knitr::opts_chunk$set(echo = TRUE)

options(digits=7)

MOVIELENS_DATA_FILE_NAME <- "arog_data.rda"
MOVIELENS_REPORT_FILE_NAME <- "arog_report.rda"

#Load the files
load(MOVIELENS_DATA_FILE_NAME)
load(MOVIELENS_REPORT_FILE_NAME)

#--------------------------------------------------------------------
# This function counts the number of N/A entries in the columns of 
# the provided data set, it returns a tibble with the columns:
#    name - storing the column name of the data set
#    count - storing the number of N/A entries
#    percent - storing the percent of N/A entries
#--------------------------------------------------------------------
count_na_entries <- function(data_set) {
  col_names <- names(data_set)
  na_counts <- as.vector(sapply(col_names, function(name){
    return(sum(is.na(data_set[,name])))
  }))
  num_rows <- nrow(data_set)
  percents <- round(na_counts*100/num_rows, 2)
  result <- tibble(name = col_names, 
                count = na_counts,
                percent = percents) %>%
    arrange(desc(count))
  names(result) <- c("Column name", "N/A count", "N/A percent")
  return(result)
}

#--------------------------------------------------------------------
# This function is used to make the number of floors summary for an
# apartment types. It accepts an apartment type and a data set, which
# defaults to arog_data$selected_data, and then returns a tibble, with 
# the following data for the flats of the app_type type:
#    app_type - apartment type
#    count - the number of non N/A numberOfFloors
#    avg - average of numberOfFloors values
#    se - standard error of numberOfFloors values
#    min - min numberOfFloors value
#    max - max numberOfFloors value
#--------------------------------------------------------------------
nr_floors_summary <- function(app_type, data_set = arog_data$selected_data) {
  df <- data_set %>%
    filter(!is.na(numberOfFloors) & (typeOfFlat == app_type)) %>% 
    summarise(app_type = app_type,
              count = n(),
              avg = round(mean(numberOfFloors), 1), 
              se = round(sd(numberOfFloors), 1),
              min = min(numberOfFloors),
              max = max(numberOfFloors))
  return(as_tibble(df))
}
```

# Introduction
<!-- An introduction/overview/executive summary section that:
 1. Describes the dataset
 2. Summarizes the goal of the project 
 3. Outlines the key steps that were performed; -->


## Dataset overview

As stated on the [webpage](`r arog_report$AROG_DATA_SET_SITE_URL`) of the `r arog_report$AROG_DATA_SET_NAME`, it contains `198,379` rental offers scraped from the Germany's biggest real estate online platform ÃŸ [ImmobilienScout24](https://www.immobilienscout24.de/). 

The data set consists of a single CSV file: *`r arog_report$AROG_CSV_FILE_NAME`* which only contains offers for rental properties. The data features important rental property attributes, such as the living area size, the rent (both base rent as well as total rent), the location, type of energy, and etc. The `date` column present in the data set defines the time of scraping, which was done on three distinct dates: *2018-09-22*, *2019-05-10* and *2019-10-08*.

The complete list of data set columns is extensive[^1] and thus in this study we will use the following subset:
```{r, echo=F}
names(arog_data$selected_data)
```
This sub-selection reduces the number of considered data set columns[^2] from $48$ to $26$ and is motivated by the personal preferences of the report's author and has no scientifically proven motivation. On the contrary, this column selection shall be seen as a part of problem statement. In other words, the task is to build an accurate[^3] rental price prediction model based on the predictors from this set of columns.

The additional data preparation steps will be described in the *"Data wrangling"* section of this document.

[^1]: Please consider reading *"Appendix A"* for the complete list of the data set columns.
[^2]: Please consider reading *"Appendix B"* for the column descriptions.
[^3]: Please consider reading the *"Project goal"* section for an exact goal formulation.

## Project goal



## Execution plan

Let us now briefly outline the main steps to be performed to reach the previously formalized project goal:

1. **Prepare the data** -- see the *"Data wrangling"* section:
    + Select, clean, and reshape relevant data; split it into training and validation sets; and etc.
2. **Analyze the dataset** -- see the *"Dataset analysis"* section:
    + Perform data exploration and visualization; summarize insights on the data.
3. **Describe the modeling approach** -- see the *"Modeling approach"* section:
    + Consider the insights of the data analysis; suggest the way for building the prediction model.
4. **Present modeling results** -- see the  *"Results"* section:
    + Train the model on the `modeling` set; analyze the training results; evaluate on the `validation` set.
5. **Provide concluding remarks** -- see the *"Conclusions"* section:
    + Summarize the results; mention any approach limitations; outline possible future improvements.

# Data wrangling
<!-- A data wrangling section that explains how the data was prepared for data analysis -->
In this section we present cleaning, enriching, and restructuring the raw data taken from the `r arog_report$AROG_DATA_SET_NAME`.

This section will be organized as follows: First we explain how we cleaned the data and solved some of its inconsistencies, by enriching the data. Then we identify some structural changes done to the data. Further, we
provide a summary of the wrangled data set. In the end, we explain how we split the entire data set into the `validation` and `modeling` sub-sets[^4].

[^4]:The latter will also be split into the `training` and `testing` set for the sake of model cross-validation.

## Data cleaning & enriching
Let us note that the number of data entries in the original data set is equal to `r nrow(arog_data$selected_data)`. This data is however not ready to be worked with as it is very dirty.  It contains multiple `N/A` values; is inconsistent -- has  mismatching row values, e.g. `floor = 10` and `typeOfFlat = "roof_storey"`; and has multiple outliers in numerical/integer columns.

The rest of the section is organized as follows:  First, we explain cleaning of `N/A` values. Second, we discuss stripping of the data from the outliers. Third, we outline filtering out and correcting some of the data inconsistencies.

### Removing `N/A` values 
Consider for example the next table summarizing the number of `N/A` values per data set column:

```{r, echo=F}
sel_data_na_cnts <- count_na_entries(arog_data$selected_data)
sel_data_na_cnts%>% print(., n=Inf)
```
As one can see, about $\frac{1}{2}$ of the columns has $2.5$--$80$% `N/A`$^{s}$, whereas the other half has (almost) no `N/A`$^{s}$.

Cleaning the data from `N/A` values will be explained in the next steps:

1. We begin with the `totalRent` column as this is the value that we want to predict;
2. We proceed with the columns with the marginal ($< 1$%) of `N/A` values; 
3. We cover the remaining columns in the descending order of the number of `N/A` values.

#### The first steps

```{r, echo = F}
idx <- which(sel_data_na_cnts[,"Column name"] == "totalRent")
total_rent_na_percent <- sel_data_na_cnts[idx, "N/A percent"]
num_marginal_columns <- nrow(filter(sel_data_na_cnts, sel_data_na_cnts[,"N/A percent"] < 1))
```

The `totalRent` column contains data that we want to predict. Therefore, the rows with `totalRent` == `N/A` are useless to us and shall be removed. Unfortunately, this will reduce the data set by `r total_rent_na_percent`%. There are also `r num_marginal_columns` columns with a marginal ($0$ to $1$) number of `N/A` values. The latter can be seamlessly removed as even if all of these `N/A`$^{s}$ appear in different rows, we will remove at most `r num_marginal_columns` entries which is just `r round(num_marginal_columns/nrow(arog_data$selected_data)*100,4)`% of data.

#### The main columns
Let us consider the columns one by one. Note that, some modifications we will do to the data to remove the `N/A` values  may introduce bias. To for test that we would need a clean data set with no `N/A` values initially present and then to use such a data set for the trained model(s) validation. Due to the lack of time this will not be done in the case study.

##### Column: `electricityBasePrice` - $76.2$% `N/A` values
We will set the electricity base price for the `N/A` values to zero. The motivation is that, since the number of `N/A` values is almost $80$% and no other zero values are present:
```{r}
x <- arog_data$selected_data %>% filter(!is.na(electricityBasePrice))
sum(x$electricityBasePrice == 0)
```
it is likely that the `N/A` values were used to determine the fact that there is no electricity base price.

##### Column: `energyEfficiencyClass` - $72.3$% `N/A` values
The energy efficiency factor levels are: 
```{r}
levels(arog_data$selected_data$energyEfficiencyClass)
```
So we shall naturally set all the `N/A` energy efficiency levels to `"NO_INFORMATION"`.

##### Column: `heatingCosts` - $68.2$% `N/A` values
```{r, echo = F}
x <- arog_data$selected_data %>% filter(!is.na(heatingCosts))
num_zero_val <- sum(x$heatingCosts == 0)
```
We will set the heating costs for the `N/A` values to zero as there are already  `r num_zero_val` zero-valued heating cost entries. It is unlikely that there are non-heated accommodations in Germany so *we assume that the $0$ values, the same as `N/A`$^{s}$ mean - "unknown"*.

##### Column: `noParkSpaces` - $65.8$% `N/A` values
```{r, echo = F}
x <- arog_data$selected_data %>% filter(!is.na(noParkSpaces))
num_zero_val <- sum(x$noParkSpaces == 0)
```
We will set the number of parking places for the `N/A` values to zero as there is already `r num_zero_val` zero-valued entries. By this step we assume that, `N/A` is interpreted as *"not applicable"* or *"no are available"*.

##### Column: `interiorQual` - $38.8$% `N/A` values
The interior quality factor levels are: 
```{r}
levels(arog_data$selected_data$interiorQual)
```
So we shall introduce a new level for the `N/A` values, called `"unknown"`.

##### Column: `numberOfFloors` - $36.2$% `N/A` values
```{r, echo = F}
type_of_flat_levels <- levels(arog_data$selected_data$typeOfFlat)
list_of_nof_sum <- sapply(type_of_flat_levels, nr_floors_summary)
nof_sum_df <- as_tibble(t(list_of_nof_sum)) %>% arrange(desc(as.numeric(count)))
```
Setting the `N/A` values for the floors shall be agreed with the apartment type, if we gather some number of floors statistics for each available apartment type we get the following:

```{r, echo = F}
kable(nof_sum_df, caption = "Type of flat vs. number of floors statistics",
      col.names = c("typeOfFlat", "Count", "Average", "Standard error", "Minimum", "Maximum"),
      escape = TRUE, align=rep('c', 4)) %>%
  add_header_above(c(" " = 1, "numberOfFloors" = 5)) %>%
  kable_styling(latex_options =c("striped", "HOLD_position"))
```
From where we conclude that the data we have is very polluted. Clearly, one can not expect apartments with $99$ floors and alike. See also on the large average (all  `+/-` around $3$ floors) and the huge standard error values. If we visualize the results (filtering out `r sum(arog_data$selected_data$numberOfFloors > arog_report$MAX_NUM_FLOORS_TO_CONSIDER, na.rm = TRUE)` flats with more than `r arog_report$MAX_NUM_FLOORS_TO_CONSIDER` floors), we see that:

```{r, echo = F}
arog_data$selected_data %>%
  filter(!is.na(numberOfFloors) & !is.na(typeOfFlat) &
           (numberOfFloors <= arog_report$MAX_NUM_FLOORS_TO_CONSIDER)) %>%
  group_by(typeOfFlat) %>%
  ggplot() +
    geom_bar(aes(numberOfFloors)) +
    scale_y_log10() +
    facet_wrap(~typeOfFlat, nrow=3) +
  theme(plot.title = element_text(hjust = 0.5, face="bold")) +
  labs(x="The number of floors") +
  ggtitle("The distribution of number of floors per flat type") +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
the data seems to be approximately normally distributed (except for the `apartment` type) with the mean values within $2.5$ - $4.0$ range. This makes us believe that this data is too much biased and polluted. So we will not rely on this column in our analysis.

##### Column: `condition` - $25.4$% `N/A` values
The condition factor levels are: 
```{r, echo = F}
levels(arog_data$selected_data$condition)
```
So we shall introduce a new level for the `N/A` values, called `"unknown"`.

##### Column: `yearConstructed` - $21.3$% `N/A` values
There is no good default to replace the `N/A` values here. Yet, it is a significant amount of data which we do not want to exclude. Therefore drop this column from the analysis and just use the `newlyConst` flag column.

##### Column: `floor` - $19.0$% `N/A` values
We could assign some `floor` values based on the flat types:
```{r, echo = F}
levels(arog_data$selected_data$typeOfFlat)
```
For example, we could consider assigning:

* `half_basement` -- set `floor` to be the average half-basement floor value
* `ground_floor` -- set `floor = 0`
* `raised_ground_floor` -- set `floor` to be the average raised ground floor value 

but, let us look at the floor values (filtering out `r sum(arog_data$selected_data$floor > arog_report$MAX_FLOOR_TO_CONSIDER, na.rm = TRUE)` flats higher that at the `r arog_report$MAX_FLOOR_TO_CONSIDER`'th floor), for these flat types:
```{r, echo = F, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  filter(!is.na(floor) & !is.na(typeOfFlat) & (floor <= arog_report$MAX_FLOOR_TO_CONSIDER) &
           (typeOfFlat %in% c("half_basement", "ground_floor", "raised_ground_floor"))) %>%
  group_by(typeOfFlat) %>%
  ggplot() +
  geom_bar(aes(floor)) +
  scale_y_log10() +
  facet_wrap(~typeOfFlat, nrow=3) +
  labs(x="The flat's floor") +
  ggtitle("The distribution of floors per flat type") +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
From the data above we see that we shall not only correct the `N/A` values but set all of the floor values for the considered flat types as follows:

* `half_basement` -- set `floor = -1`
* `ground_floor` -- set `floor = 0`
* `raised_ground_floor` -- set `floor = 0`

```{r, echo = F}
num_rem_na_floors <- arog_data$selected_data %>%
  filter(is.na(floor) & !is.na(typeOfFlat) &
           !(typeOfFlat %in% c("half_basement", "ground_floor", "raised_ground_floor"))) %>%
  nrow()
```

If we do that then there will still be `r num_rem_na_floors` (`r round(num_rem_na_floors*100/nrow(arog_data$selected_data), 1)`% of data) `N/A` floor values for the flat types for which we can not give any exact value. So we will just assign those to the mean floor value in the category.

##### Column: `heatingType` - $16.4$% `N/A` values
The heating type factor levels are: 
```{r, echo = F}
levels(arog_data$selected_data$heatingType)
```
So we shall introduce a new level for the `N/A`, and `"H"` values, called `"unknown"`.

##### Column: `typeOfFlat` - $13.9$% `N/A` values
The type of flat factor levels are: 
```{r, echo = F}
levels(arog_data$selected_data$typeOfFlat)
```
So we shall introduce a new level for the `N/A` values, called `"unknown"`. Note that, we do not use the pre-defined level `"other"` here as we interpret it as known flat type which is just not on the list of available choices.

##### Column `serviceCharge` - $2.58$% `N/A` values
We will set the service charges for the `N/A` values to zero. The motivation is that, there are:
```{r}
x <- arog_data$selected_data %>% filter(!is.na(serviceCharge))
sum(x$serviceCharge == 0)
```
zero values present, so we interpret the `N/A` values as defining the fact of no additional service charges.

### Filtering outliers
In this section we only considered the numeric/integer columns of the data set. The initial set of outliers per column is obtained using: ```{r, eval = F}
boxplot.stats(.)$out
```
However, not all of the obtained outlier values are the true outliers. It may be that some flats do stand out as examples of extraordinary property, and not due to owner input errors. This is why, for each of the column, the identified outliers are analyzed and it is then decided on how much of them is to be removed. 

#### Column: `noRooms`
The `noRooms` column has `r length(boxplot.stats(arog_data$selected_data$noRooms)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=noRooms)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Number of rooms") +
  ggtitle("Outliers of the number of rooms") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `noRooms` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$noRooms[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$noRooms[2]`].

#### Column: `noParkSpaces`
The `noParkSpaces` column has `r length(boxplot.stats(arog_data$selected_data$noParkSpaces)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=noParkSpaces)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Number of parking spaces") +
  ggtitle("Outliers of the number of parking spaces") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `noParkSpaces` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$noParkSpaces[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$noParkSpaces[2]`].

#### Column: `livingSpace`
The `livingSpace` has `r length(boxplot.stats(arog_data$selected_data$livingSpace)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=livingSpace)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Living space") +
  ggtitle("Outliers of the living space") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `livingSpace` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$livingSpace[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$livingSpace[2]`].

#### Column: `baseRent`
The `baseRent` has `r length(boxplot.stats(arog_data$selected_data$baseRent)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=baseRent)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Base rent") +
  ggtitle("Outliers of the base rent") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `baseRent` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$baseRent[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$baseRent[2]`].

#### Column: `electricityBasePrice`
The `electricityBasePrice` has `r length(boxplot.stats(arog_data$selected_data$electricityBasePrice)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=electricityBasePrice)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Electricity base price") +
  ggtitle("Outliers of the electricity base price") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `electricityBasePrice` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$electricityBasePrice[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$electricityBasePrice[2]`].

#### Column: `heatingCosts`
The `heatingCosts` has `r length(boxplot.stats(arog_data$selected_data$heatingCosts)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=heatingCosts)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Heating costs") +
  ggtitle("Outliers of the heating costs") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `heatingCosts` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$heatingCosts[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$heatingCosts[2]`].

#### Column: `serviceCharge`
The `serviceCharge` has `r length(boxplot.stats(arog_data$selected_data$serviceCharge)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=serviceCharge)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Service charge") +
  ggtitle("Outliers of the service charge") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `serviceCharge` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$serviceCharge[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$serviceCharge[2]`].

#### Column: `totalRent`
The `totalRent` has `r length(boxplot.stats(arog_data$selected_data$totalRent)$out)` outliers, see the plot:
```{r, echo = F, warning=FALSE, out.height = "35%", fig.align="center"}
arog_data$selected_data %>%
  ggplot(aes(x="", y=totalRent)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() + 
  labs(x="All flats", y="Total rent") +
  ggtitle("Outliers of the total rent") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
We shall remove all the rows with `totalRent` outside the interval
[`r arog_report$MIN_MAX_OUTLIER_FILTERS$totalRent[1]`, `r arog_report$MIN_MAX_OUTLIER_FILTERS$totalRent[2]`].

### Fixing inconsistencies
In addition to the data alternations done above we have also done the following:

* Re-setting the number of floors:
    * `half_basement` --`floor` $= -1$
    * `ground_floor` -- `floor` $= 0$
    * `raised_ground_floor` --`floor` $= 0$
* Filter out flats:
    * Other than `"half_basement"`, `"other"`, and `"unknown"`; but with `floor` < $0$
    * With zero `totalRent` values (`r length(which(arog_data$selected_data$totalRent == 0))` entries)

There may be more inconsistencies present in the data, for example we expect that:
```
totalRent = baseRent + electricityBasePrice + heatingCosts + serviceCharge
```
which may not be the case. Unfortunately due to the lack of time these were not analyzed further and thus may potentially influence the "accuracy" of the trained statistical model.

## Restructuring data

There data set at hand does not have any complex structure. However, because we want to be able to do predictions per city and avoid cities with the same names within different lands and regions we shall combine the `regio` columns into a new single one, as follows:
```{r, eval =F}
  clean_arog_data <- clean_arog_data %>% 
    unite("location", c("regio1", "regio2", "regio3"), remove=FALSE) %>%
    select(-regio1, -regio2, -regio3)
```
The resulting columns have values constructed according to the following pattern:
```
location = regio1 + "_" + regio2 + "_" + regio3
```
For example:
```{r}
arog_data$wrangled_data$location[1:5]
```

In addition we have rounded and turned into integer columns all the integer-valued columns of the data set:
```{r}
c("floor", "noParkSpaces", "noRooms")
```

## Wrangled data set
Let us now summarize the resulting clean data:

```{r, echo=F}
clean_data_na_cnts <- count_na_entries(arog_data$wrangled_data)
clean_data_na_cnts%>% print(., n=Inf)
```

```{r, echo = F}
selected_data_row_cnt <- nrow(arog_data$selected_data)
cleaned_data_row_cnt <- nrow(arog_data$wrangled_data)
na_total_rent_cnt <- round(selected_data_row_cnt/100*total_rent_na_percent)
selected_wtr <- nrow(arog_data$selected_data) - na_total_rent_cnt
```

As one can notice, the dat set size has been reduced from `r  nrow(arog_data$selected_data)` to `r cleaned_data_row_cnt`. The major reason for that is excluding the rows with the `N/A` values of the `totalRent` column. Let us recall that the number of such raws was `r total_rent_na_percent`% of the data set, e.g. `r na_total_rent_cnt` rows. It now remains to notice that `r nrow(arog_data$selected_data)` $-$ `r na_total_rent_cnt` $=$ `r selected_wtr` $>$ `r cleaned_data_row_cnt`. The remaining delta of `r selected_wtr - cleaned_data_row_cnt` rows ($\approx$ `r round( (selected_wtr - cleaned_data_row_cnt)*100/selected_data_row_cnt, 1)`% of data) is explained by cleaning the `floor`/`typeOfFlat` columns, filtering-out outliers, and etc.

The data has been cleaned but we can expect that there is some noise in the data which we have not addressed. We might get more data-quality insights when we perform data analysis in the subsequent sections.

## Splitting data

To facilitate supervised learning, the wrangled data is split into the `modeling`, `r (1-arog_report$VALIDATION_TO_MODELING_SET_RATIO)*100`% of data, and `validation`, `r arog_report$VALIDATION_TO_MODELING_SET_RATIO*100`% of data, sets. The former will be used for training statistical model(s) and the latter for the model(s) validation. Note that, for the sake of subsequent cross validation during modeling part, we further split the `modeling` set into the `training`, `r (1-arog_report$TEST_TO_TRAIN_SET_RATIO)*100`% thereof, and `testing`, `r arog_report$TEST_TO_TRAIN_SET_RATIO*100`% thereof, sets.

We split the data in the following steps:

1. The data is randomly split into to parts according to the specified ratio:
```{r, eval = F}
  test_index <- createDataPartition(y = data_set$totalRent, times = 1, 
                                    p = ratio, list = FALSE)
```
2. The `test_index` rows are the candidates for the `testing`/`validation` set rows
3. The factorized column values of the `testing`/`validation` set are considered:
```{r}
str_data <- capture.output(str(arog_data$wrangled_data))
str_replace_all(str_subset(str_data, "Factor"), "levels.*","levels ...")
```
4. The rows with the values not present in the `testing`/`modeling` set are dropped 
5. The `testing`/`modeling` set consists of rows absent in the `testing`/`validation` set

The procedure above ensures that the `testing`/`validation` set can always be evaluated on a model trained on the `testing`/`modeling` set. For more details, see the `create_arog_data` and `split_train_test_sets` functions located in the `apartment_rental_project.R` script.

The resulting set sizes are as follows:
```{r, echo = F}
total_data_size <- nrow(arog_data$wrangled_data)
train_set_size <- nrow(arog_data$training_data)
test_set_size <- nrow(arog_data$testing_data)
model_set_size <- train_set_size + test_set_size
valid_set_size <- nrow(arog_data$validation)
```
* `modeling` -- `r model_set_size` rows, `r round(model_set_size*100/total_data_size, 1)`% of data
    * `training` -- `r train_set_size` rows, `r round(train_set_size*100/model_set_size, 1)`% of `modeling` set
    * `testing` -- `r test_set_size` rows, `r round(test_set_size*100/model_set_size, 1)`% of `modeling` set
* `validation` -- `r valid_set_size` rows, `r round(valid_set_size*100/total_data_size, 1)`% of data

As expected, due to returning `testing`/`validation` set rows to the `testing`/`modeling` set for consistency, the desired set ratios are biased. The `validation` set size is almost as prescribed (`r arog_report$VALIDATION_TO_MODELING_SET_RATIO*100`% of data), but the `testing` set size is affected more significantly[^6]. Yet, we see no issue as the `testing` set is still $> 10$% of the `modeling` set, which should be enough for performing cross validation.

[^6]: The requested `testing` set size was `r arog_report$TEST_TO_TRAIN_SET_RATIO*100`% of the `modeling` set.

# Data analysis
<!-- A data analysis section that:
 1. Explains the process and techniques used, such as:
  1.1 Data exploration
  1.2 Data visualization
 2. Presents insights gained -->

In this sections we analyze the `training` subset of the original data set only, as we assume that this is the only data available for building the prediction models. The motivation behind is that we want to avoid influencing the model testing and validation results. This is done under a, not-verified, assumption that the the `testing` set, follows the same probability distribution of the conditional probability of interest as the `validation` set. In the *"Results"* section we may come back to this assumption in case the accuracy of the developed statistical model(s) on the `validation` set will turn out to be insufficient.

In this section we shall use data visualization and other techniques to investigate the properties of the data we could use to build the prediction model.

## Analyzing flat locations
Let us first notice that the number of flats listed by location seems to follow the same pattern on all of the three data scraping dates. 

```{r, echo = F, out.height = "35%", fig.align="center"}
arog_data$wrangled_data %>%
  ggplot() + geom_bar(aes(location)) + scale_y_sqrt() +
  labs(x="Various locations", y="Number of flats") +
  ggtitle("Flat counts per location on different dates") +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  facet_wrap(~date, nrow=3) +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```

The distribution of flat counts per location, for all the dates, indicates that there are a lot of locations with just one flat. However, there are also a few locations with extremely large number of flats.

```{r, echo = F, out.height = "35%", fig.align="center"}
offers_per_location <- arog_data$wrangled_data %>% 
  group_by(location) %>% 
  summarize(cnt = n())

offers_per_location %>%
  ggplot(aes(x=cnt)) + 
  scale_x_log10() +
  labs(x="Number of flats", y="Number of locations") +
  ggtitle("Distribution of location flat counts") +
  geom_histogram(binwidth=.05) +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```

As follows from the next plot, the median value for the number of flats per location is around $5$.

```{r, echo = F, out.height = "35%", fig.align="center"}
offers_per_location %>% 
  ggplot(aes(x = "", y = cnt))  + 
  #coord_cartesian(ylim = c(0, 40)) + 
  geom_boxplot(outlier.colour = "red", outlier.alpha = 0.3, outlier.shape = 1, outlier.size = 1) + 
  scale_y_log10() +
  labs(x="All locations", y="Number of flats per location") +
  ggtitle("Flat counts per location") +
  annotation_logticks() + theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```

Let us plot the `totalRent` per location flat count, ordered by the count. We shall exclude the `totalRent` values below $150$ (`r sum(arog_data$wrangled_data$totalRent <= 150)` entries) for the sake of better visualization. Also to show the trend we will use `ggplot` with `geom_smooth(method = 'gam')`.

```{r, echo = F, out.height = "35%", fig.align="center"}
left_join(arog_data$wrangled_data, offers_per_location, by="location") %>% 
  arrange(cnt) %>% #filter(totalRent > 150) %>%
  ggplot(aes(x=cnt, y=totalRent)) +
  geom_point(alpha=0.05) +
  scale_x_log10() +
  #scale_y_log10() +
  geom_smooth(method = 'gam') +
  labs(x="Number of flats in location", y="Flat total rent") +
  ggtitle("The total rent vs. the number of flats per location") +
  theme(plot.title = element_text(hjust = 0.5, face="bold"))
```
Clearly, there is a trend in that the places with more flat offers have on-average lower `totalRent` values.



# Modeling approach
<!-- A modeling approach section that explains the modeling approach -->



# Results
<!-- A results section that:
 1. Presents the modeling results 
 2. Discusses the model performance -->



# Conclusions
<!-- A conclusion section that:
 1. Gives a brief summary of the report
 2. Explains its limitations
 3. Suggests future work -->
 
## Future work

Check for introducing any bias by data wrangling.

# Appendix A: The complete list of data set columns

Hereby we present the complete list of columns from the original `r arog_report$AROG_DATA_SET_NAME`:

```{r, echo = F}
names(arog_data$raw_data)
```

# Appendix B: Data set column descriptions

Here is the list of the initially considered data set columns with the descriptions thereof:

1. `hasKitchen` -- has a kitchen
2. `balcony` -- does the object have a balcony
3. `cellar` -- has a cellar
4. `lift` -- is elevator available
5. `floor` -- which floor is the flat on
6. `garden` -- has a garden
7. `noParkSpaces` -- number of parking spaces
8. `livingSpace` -- living space in sqm
9. `condition` -- condition of the flat
10. `interiorQual` -- interior quality

11. `regio1` --  Bundesland
12. `regio2` - District or Kreis, same as geo krs
13. `regio3` -- City/town

14. `noRooms` -- number of rooms
15. `numberOfFloors` -- number of floors in the building
16. `typeOfFlat` -- type of flat
17. `yearConstructed` -- construction year
18. `newlyConst` -- is the building newly constructed
19. `heatingType` -- Type of heating
20. `energyEfficiencyClass` -- energy efficiency class

21. `heatingCosts` -- monthly heating costs in â‚¬
22. `serviceCharge` --  auxiliary costs such as electricity or Internet in â‚¬
23. `electricityBasePrice` -- monthly base price for electricity in â‚¬
24. `baseRent` -- base rent without electricity and heating
25. `totalRent` -- total rent (usually a sum of base rent, service charge and heating cost)

26. `date` -- time of scraping
